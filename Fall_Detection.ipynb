{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAoymCoHmo_L"
      },
      "source": [
        " VILLAR GARCIA Jessica Mariana\n",
        " \n",
        " BEJINARIU George \n",
        "# Machine Learning Project\n",
        "## Fall detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI-PIVC-m1GH"
      },
      "source": [
        "The aim of this project is to study the ability of different classification models to detect fall thanks to some indicators.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1Wzmye3rjE"
      },
      "source": [
        "# Libraries \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D7OETuWn5ma"
      },
      "source": [
        "### The Data \n",
        "\n",
        "The dataset 'falldata' contains a sample of 2821 observations describing the walk of several people. The features correspond to 87 indicators computed on either the raw signals, the derivative of the signal or the energy of the signals. The response variable, fall or no fall, is described by a binary label. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGfBT0xG4HLz",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "202fafc6-7cd2-4582-b2cd-8e27263c1162"
      },
      "source": [
        "# Choose File to be uploaded (falldataproject.csv)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42739058-2d46-4640-afab-ec5218cae6f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-42739058-2d46-4640-afab-ec5218cae6f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving falldataproject.csv to falldataproject.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_FEw4RnW3SB"
      },
      "source": [
        "# Data set\n",
        "data = pd.read_csv('falldataproject.csv')\n",
        "y = data['FALL']\n",
        "x = data.iloc[:,1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "nC5M8ixgXNxh",
        "outputId": "30cfc3ce-4d97-4a2d-e6ec-bd8210b769f9"
      },
      "source": [
        "# Data set view\n",
        "# 87 indicators\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "      <th>raw_feat_X1</th>\n",
              "      <th>raw_feat_X2</th>\n",
              "      <th>raw_feat_X3</th>\n",
              "      <th>raw_feat_X4</th>\n",
              "      <th>raw_feat_X5</th>\n",
              "      <th>raw_feat_X6</th>\n",
              "      <th>raw_feat_X7</th>\n",
              "      <th>raw_feat_X8</th>\n",
              "      <th>raw_feat_X9</th>\n",
              "      <th>raw_feat_X10</th>\n",
              "      <th>raw_feat_X11</th>\n",
              "      <th>raw_feat_X12</th>\n",
              "      <th>raw_feat_X13</th>\n",
              "      <th>raw_feat_X14</th>\n",
              "      <th>raw_feat_X15</th>\n",
              "      <th>raw_feat_X16</th>\n",
              "      <th>raw_feat_X17</th>\n",
              "      <th>raw_feat_X18</th>\n",
              "      <th>raw_feat_X19</th>\n",
              "      <th>raw_feat_X20</th>\n",
              "      <th>raw_feat_X21</th>\n",
              "      <th>raw_feat_X22</th>\n",
              "      <th>raw_feat_X23</th>\n",
              "      <th>raw_feat_X24</th>\n",
              "      <th>raw_feat_X25</th>\n",
              "      <th>raw_feat_X26</th>\n",
              "      <th>raw_feat_X27</th>\n",
              "      <th>raw_feat_X28</th>\n",
              "      <th>raw_feat_X29</th>\n",
              "      <th>fft_feat_X1</th>\n",
              "      <th>fft_feat_X2</th>\n",
              "      <th>fft_feat_X3</th>\n",
              "      <th>fft_feat_X4</th>\n",
              "      <th>fft_feat_X5</th>\n",
              "      <th>fft_feat_X6</th>\n",
              "      <th>fft_feat_X7</th>\n",
              "      <th>fft_feat_X8</th>\n",
              "      <th>fft_feat_X9</th>\n",
              "      <th>fft_feat_X10</th>\n",
              "      <th>...</th>\n",
              "      <th>fft_feat_X20</th>\n",
              "      <th>fft_feat_X21</th>\n",
              "      <th>fft_feat_X22</th>\n",
              "      <th>fft_feat_X23</th>\n",
              "      <th>fft_feat_X24</th>\n",
              "      <th>fft_feat_X25</th>\n",
              "      <th>fft_feat_X26</th>\n",
              "      <th>fft_feat_X27</th>\n",
              "      <th>fft_feat_X28</th>\n",
              "      <th>fft_feat_X29</th>\n",
              "      <th>deriv_feat_X1</th>\n",
              "      <th>deriv_feat_X2</th>\n",
              "      <th>deriv_feat_X3</th>\n",
              "      <th>deriv_feat_X4</th>\n",
              "      <th>deriv_feat_X5</th>\n",
              "      <th>deriv_feat_X6</th>\n",
              "      <th>deriv_feat_X7</th>\n",
              "      <th>deriv_feat_X8</th>\n",
              "      <th>deriv_feat_X9</th>\n",
              "      <th>deriv_feat_X10</th>\n",
              "      <th>deriv_feat_X11</th>\n",
              "      <th>deriv_feat_X12</th>\n",
              "      <th>deriv_feat_X13</th>\n",
              "      <th>deriv_feat_X14</th>\n",
              "      <th>deriv_feat_X15</th>\n",
              "      <th>deriv_feat_X16</th>\n",
              "      <th>deriv_feat_X17</th>\n",
              "      <th>deriv_feat_X18</th>\n",
              "      <th>deriv_feat_X19</th>\n",
              "      <th>deriv_feat_X20</th>\n",
              "      <th>deriv_feat_X21</th>\n",
              "      <th>deriv_feat_X22</th>\n",
              "      <th>deriv_feat_X23</th>\n",
              "      <th>deriv_feat_X24</th>\n",
              "      <th>deriv_feat_X25</th>\n",
              "      <th>deriv_feat_X26</th>\n",
              "      <th>deriv_feat_X27</th>\n",
              "      <th>deriv_feat_X28</th>\n",
              "      <th>deriv_feat_X29</th>\n",
              "      <th>FALL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.249744</td>\n",
              "      <td>-0.162770</td>\n",
              "      <td>0.223727</td>\n",
              "      <td>0.393904</td>\n",
              "      <td>-0.154366</td>\n",
              "      <td>0.128968</td>\n",
              "      <td>1.090661</td>\n",
              "      <td>0.913849</td>\n",
              "      <td>0.505526</td>\n",
              "      <td>-0.105793</td>\n",
              "      <td>-0.195484</td>\n",
              "      <td>-0.583576</td>\n",
              "      <td>-0.185653</td>\n",
              "      <td>0.223045</td>\n",
              "      <td>0.003446</td>\n",
              "      <td>-0.103057</td>\n",
              "      <td>0.480750</td>\n",
              "      <td>0.781277</td>\n",
              "      <td>-0.119297</td>\n",
              "      <td>-0.994378</td>\n",
              "      <td>0.152711</td>\n",
              "      <td>0.114531</td>\n",
              "      <td>0.527218</td>\n",
              "      <td>0.684310</td>\n",
              "      <td>0.226488</td>\n",
              "      <td>0.214075</td>\n",
              "      <td>0.525904</td>\n",
              "      <td>-1.095983</td>\n",
              "      <td>1.919093</td>\n",
              "      <td>-0.449884</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>0.463316</td>\n",
              "      <td>0.274141</td>\n",
              "      <td>-0.218774</td>\n",
              "      <td>-0.048435</td>\n",
              "      <td>-1.033262</td>\n",
              "      <td>-0.812810</td>\n",
              "      <td>-0.683375</td>\n",
              "      <td>-0.455641</td>\n",
              "      <td>...</td>\n",
              "      <td>0.517962</td>\n",
              "      <td>0.052870</td>\n",
              "      <td>0.000862</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>0.087599</td>\n",
              "      <td>0.083742</td>\n",
              "      <td>0.790298</td>\n",
              "      <td>1.111155</td>\n",
              "      <td>-0.184972</td>\n",
              "      <td>0.657302</td>\n",
              "      <td>-0.227088</td>\n",
              "      <td>-0.252275</td>\n",
              "      <td>-1.100050</td>\n",
              "      <td>-0.103071</td>\n",
              "      <td>0.237298</td>\n",
              "      <td>2.326422</td>\n",
              "      <td>2.364639</td>\n",
              "      <td>1.891086</td>\n",
              "      <td>0.052099</td>\n",
              "      <td>-0.103057</td>\n",
              "      <td>0.131791</td>\n",
              "      <td>-0.116826</td>\n",
              "      <td>0.419307</td>\n",
              "      <td>-1.299307</td>\n",
              "      <td>-0.093961</td>\n",
              "      <td>-0.709053</td>\n",
              "      <td>-1.045640</td>\n",
              "      <td>0.283405</td>\n",
              "      <td>-0.676243</td>\n",
              "      <td>0.121241</td>\n",
              "      <td>0.734862</td>\n",
              "      <td>0.179370</td>\n",
              "      <td>0.402461</td>\n",
              "      <td>0.638393</td>\n",
              "      <td>0.344236</td>\n",
              "      <td>0.823239</td>\n",
              "      <td>-0.409350</td>\n",
              "      <td>1.425206</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.385843</td>\n",
              "      <td>-0.660978</td>\n",
              "      <td>-0.127798</td>\n",
              "      <td>-0.205710</td>\n",
              "      <td>-0.160936</td>\n",
              "      <td>0.111606</td>\n",
              "      <td>0.171391</td>\n",
              "      <td>2.889781</td>\n",
              "      <td>0.377333</td>\n",
              "      <td>0.602582</td>\n",
              "      <td>-0.204411</td>\n",
              "      <td>-0.724876</td>\n",
              "      <td>-0.186407</td>\n",
              "      <td>0.510015</td>\n",
              "      <td>0.003446</td>\n",
              "      <td>-0.019068</td>\n",
              "      <td>-0.818148</td>\n",
              "      <td>-0.664431</td>\n",
              "      <td>0.376651</td>\n",
              "      <td>-0.626828</td>\n",
              "      <td>0.387287</td>\n",
              "      <td>1.476641</td>\n",
              "      <td>0.866832</td>\n",
              "      <td>0.959403</td>\n",
              "      <td>0.311288</td>\n",
              "      <td>0.449926</td>\n",
              "      <td>0.367252</td>\n",
              "      <td>-1.158551</td>\n",
              "      <td>1.778148</td>\n",
              "      <td>-0.646348</td>\n",
              "      <td>-0.355812</td>\n",
              "      <td>-0.491957</td>\n",
              "      <td>0.167070</td>\n",
              "      <td>-0.219944</td>\n",
              "      <td>-0.051636</td>\n",
              "      <td>-1.178882</td>\n",
              "      <td>-0.871564</td>\n",
              "      <td>-0.704800</td>\n",
              "      <td>-0.455712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.815871</td>\n",
              "      <td>0.104235</td>\n",
              "      <td>-0.111211</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>-0.190016</td>\n",
              "      <td>-0.186805</td>\n",
              "      <td>0.791372</td>\n",
              "      <td>-0.610703</td>\n",
              "      <td>1.517499</td>\n",
              "      <td>0.563679</td>\n",
              "      <td>-0.710151</td>\n",
              "      <td>-0.252275</td>\n",
              "      <td>0.192193</td>\n",
              "      <td>-0.018958</td>\n",
              "      <td>0.483344</td>\n",
              "      <td>-2.196963</td>\n",
              "      <td>2.772897</td>\n",
              "      <td>-1.889601</td>\n",
              "      <td>0.071416</td>\n",
              "      <td>-0.019068</td>\n",
              "      <td>0.147795</td>\n",
              "      <td>-0.053961</td>\n",
              "      <td>0.648177</td>\n",
              "      <td>-0.214179</td>\n",
              "      <td>-0.005129</td>\n",
              "      <td>0.642421</td>\n",
              "      <td>0.419777</td>\n",
              "      <td>0.476751</td>\n",
              "      <td>0.549323</td>\n",
              "      <td>-0.182778</td>\n",
              "      <td>0.357499</td>\n",
              "      <td>-0.056181</td>\n",
              "      <td>0.840313</td>\n",
              "      <td>0.605672</td>\n",
              "      <td>0.655029</td>\n",
              "      <td>1.052671</td>\n",
              "      <td>-0.177353</td>\n",
              "      <td>1.613721</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3.344528</td>\n",
              "      <td>-4.535931</td>\n",
              "      <td>0.165140</td>\n",
              "      <td>-0.228745</td>\n",
              "      <td>3.203818</td>\n",
              "      <td>3.379462</td>\n",
              "      <td>1.089901</td>\n",
              "      <td>2.097552</td>\n",
              "      <td>0.877990</td>\n",
              "      <td>0.200807</td>\n",
              "      <td>3.039838</td>\n",
              "      <td>0.706419</td>\n",
              "      <td>2.898928</td>\n",
              "      <td>3.938749</td>\n",
              "      <td>4.481602</td>\n",
              "      <td>3.694243</td>\n",
              "      <td>0.174268</td>\n",
              "      <td>-0.122291</td>\n",
              "      <td>5.761222</td>\n",
              "      <td>0.255291</td>\n",
              "      <td>-4.421517</td>\n",
              "      <td>4.881914</td>\n",
              "      <td>0.187604</td>\n",
              "      <td>0.330619</td>\n",
              "      <td>3.273877</td>\n",
              "      <td>3.834530</td>\n",
              "      <td>2.093866</td>\n",
              "      <td>-0.330219</td>\n",
              "      <td>3.147863</td>\n",
              "      <td>1.553830</td>\n",
              "      <td>-0.333388</td>\n",
              "      <td>-0.292473</td>\n",
              "      <td>3.390496</td>\n",
              "      <td>3.013265</td>\n",
              "      <td>3.155365</td>\n",
              "      <td>-1.071414</td>\n",
              "      <td>-0.834429</td>\n",
              "      <td>-0.692839</td>\n",
              "      <td>-0.455690</td>\n",
              "      <td>...</td>\n",
              "      <td>0.856455</td>\n",
              "      <td>0.149476</td>\n",
              "      <td>-0.106898</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>3.199629</td>\n",
              "      <td>3.220504</td>\n",
              "      <td>2.343403</td>\n",
              "      <td>-0.186892</td>\n",
              "      <td>2.891512</td>\n",
              "      <td>3.091500</td>\n",
              "      <td>-4.351699</td>\n",
              "      <td>-0.252275</td>\n",
              "      <td>-0.502388</td>\n",
              "      <td>3.694409</td>\n",
              "      <td>4.205189</td>\n",
              "      <td>-2.773949</td>\n",
              "      <td>2.276907</td>\n",
              "      <td>-2.030001</td>\n",
              "      <td>0.049545</td>\n",
              "      <td>3.694243</td>\n",
              "      <td>1.661714</td>\n",
              "      <td>3.342800</td>\n",
              "      <td>3.810750</td>\n",
              "      <td>4.777408</td>\n",
              "      <td>4.019151</td>\n",
              "      <td>0.529799</td>\n",
              "      <td>-0.779201</td>\n",
              "      <td>4.150327</td>\n",
              "      <td>-1.376566</td>\n",
              "      <td>0.425260</td>\n",
              "      <td>8.093449</td>\n",
              "      <td>-0.684318</td>\n",
              "      <td>0.046744</td>\n",
              "      <td>3.440332</td>\n",
              "      <td>3.965586</td>\n",
              "      <td>2.916183</td>\n",
              "      <td>0.367674</td>\n",
              "      <td>3.952479</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.190676</td>\n",
              "      <td>-2.884463</td>\n",
              "      <td>-1.153080</td>\n",
              "      <td>-0.698292</td>\n",
              "      <td>1.868221</td>\n",
              "      <td>2.493077</td>\n",
              "      <td>2.546198</td>\n",
              "      <td>3.817391</td>\n",
              "      <td>3.711000</td>\n",
              "      <td>2.382995</td>\n",
              "      <td>1.777882</td>\n",
              "      <td>1.274712</td>\n",
              "      <td>1.653909</td>\n",
              "      <td>3.174737</td>\n",
              "      <td>2.624805</td>\n",
              "      <td>2.059189</td>\n",
              "      <td>-0.701393</td>\n",
              "      <td>-0.664431</td>\n",
              "      <td>5.406974</td>\n",
              "      <td>0.108272</td>\n",
              "      <td>-2.193047</td>\n",
              "      <td>2.430117</td>\n",
              "      <td>-0.718033</td>\n",
              "      <td>-0.140969</td>\n",
              "      <td>3.179922</td>\n",
              "      <td>3.157377</td>\n",
              "      <td>1.748342</td>\n",
              "      <td>1.111691</td>\n",
              "      <td>1.082920</td>\n",
              "      <td>0.997529</td>\n",
              "      <td>-0.380522</td>\n",
              "      <td>-0.392840</td>\n",
              "      <td>2.490419</td>\n",
              "      <td>1.764962</td>\n",
              "      <td>2.313468</td>\n",
              "      <td>-1.063596</td>\n",
              "      <td>-0.834205</td>\n",
              "      <td>-0.693290</td>\n",
              "      <td>-0.455694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.329103</td>\n",
              "      <td>0.064652</td>\n",
              "      <td>0.021450</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>2.114421</td>\n",
              "      <td>2.130555</td>\n",
              "      <td>2.085249</td>\n",
              "      <td>-0.324901</td>\n",
              "      <td>2.729675</td>\n",
              "      <td>3.512803</td>\n",
              "      <td>-3.106884</td>\n",
              "      <td>1.376255</td>\n",
              "      <td>-0.470082</td>\n",
              "      <td>2.059326</td>\n",
              "      <td>3.056140</td>\n",
              "      <td>-1.043750</td>\n",
              "      <td>3.002674</td>\n",
              "      <td>-1.003764</td>\n",
              "      <td>0.050335</td>\n",
              "      <td>2.059189</td>\n",
              "      <td>1.714366</td>\n",
              "      <td>1.816143</td>\n",
              "      <td>3.300994</td>\n",
              "      <td>0.436898</td>\n",
              "      <td>1.755185</td>\n",
              "      <td>1.092913</td>\n",
              "      <td>-1.178860</td>\n",
              "      <td>1.056790</td>\n",
              "      <td>-3.652617</td>\n",
              "      <td>-4.743065</td>\n",
              "      <td>-0.774592</td>\n",
              "      <td>-1.076903</td>\n",
              "      <td>-0.818687</td>\n",
              "      <td>3.572430</td>\n",
              "      <td>3.409429</td>\n",
              "      <td>2.407953</td>\n",
              "      <td>1.233629</td>\n",
              "      <td>2.702845</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2.338575</td>\n",
              "      <td>-2.699941</td>\n",
              "      <td>-0.069211</td>\n",
              "      <td>-0.025849</td>\n",
              "      <td>1.420714</td>\n",
              "      <td>2.137326</td>\n",
              "      <td>1.097388</td>\n",
              "      <td>2.101987</td>\n",
              "      <td>1.200319</td>\n",
              "      <td>0.312032</td>\n",
              "      <td>1.317087</td>\n",
              "      <td>0.853486</td>\n",
              "      <td>1.177130</td>\n",
              "      <td>2.563528</td>\n",
              "      <td>1.751019</td>\n",
              "      <td>1.334773</td>\n",
              "      <td>-0.030053</td>\n",
              "      <td>-0.303004</td>\n",
              "      <td>1.439395</td>\n",
              "      <td>-2.097028</td>\n",
              "      <td>-3.483214</td>\n",
              "      <td>0.523164</td>\n",
              "      <td>-0.604828</td>\n",
              "      <td>-0.140969</td>\n",
              "      <td>2.354009</td>\n",
              "      <td>2.583982</td>\n",
              "      <td>1.714995</td>\n",
              "      <td>0.358674</td>\n",
              "      <td>1.877456</td>\n",
              "      <td>0.674087</td>\n",
              "      <td>-0.265912</td>\n",
              "      <td>-0.362163</td>\n",
              "      <td>2.088569</td>\n",
              "      <td>1.310543</td>\n",
              "      <td>1.947086</td>\n",
              "      <td>-1.074871</td>\n",
              "      <td>-0.838513</td>\n",
              "      <td>-0.694551</td>\n",
              "      <td>-0.455697</td>\n",
              "      <td>...</td>\n",
              "      <td>0.612221</td>\n",
              "      <td>0.147907</td>\n",
              "      <td>-0.087642</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>-0.152333</td>\n",
              "      <td>1.890474</td>\n",
              "      <td>1.904120</td>\n",
              "      <td>1.949577</td>\n",
              "      <td>-0.179936</td>\n",
              "      <td>2.429733</td>\n",
              "      <td>1.546721</td>\n",
              "      <td>-2.605242</td>\n",
              "      <td>1.376255</td>\n",
              "      <td>-0.389316</td>\n",
              "      <td>1.334903</td>\n",
              "      <td>2.413230</td>\n",
              "      <td>-3.414942</td>\n",
              "      <td>2.329030</td>\n",
              "      <td>-2.312024</td>\n",
              "      <td>0.054360</td>\n",
              "      <td>1.334773</td>\n",
              "      <td>1.334000</td>\n",
              "      <td>1.083955</td>\n",
              "      <td>2.146238</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>1.273051</td>\n",
              "      <td>1.261847</td>\n",
              "      <td>-0.912421</td>\n",
              "      <td>-0.103287</td>\n",
              "      <td>-2.777213</td>\n",
              "      <td>-2.766941</td>\n",
              "      <td>0.168817</td>\n",
              "      <td>-1.116162</td>\n",
              "      <td>-1.640847</td>\n",
              "      <td>1.527936</td>\n",
              "      <td>2.215856</td>\n",
              "      <td>2.353429</td>\n",
              "      <td>0.721413</td>\n",
              "      <td>2.933661</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 89 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   obs  raw_feat_X1  raw_feat_X2  ...  deriv_feat_X28  deriv_feat_X29  FALL\n",
              "0    0     0.249744    -0.162770  ...       -0.409350        1.425206     1\n",
              "1    1     0.385843    -0.660978  ...       -0.177353        1.613721     1\n",
              "2    2     3.344528    -4.535931  ...        0.367674        3.952479     1\n",
              "3    3     3.190676    -2.884463  ...        1.233629        2.702845     1\n",
              "4    4     2.338575    -2.699941  ...        0.721413        2.933661     1\n",
              "\n",
              "[5 rows x 89 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuWIJn-MI71x"
      },
      "source": [
        "#### Looking at the Data - The Imbalance\n",
        "\n",
        "We notice that there is a very big imbalance in our data. Only about 200 instances result in a fall. That means that if we design an algorithm which will always result in a \"no fall\" it will have a 92.83 % accuracy, which seems pretty good, but we know that this algorithm would be useless. Thus we have to find ways to deal with the data imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kyyKareIwfd",
        "outputId": "812af256-1c8f-4809-b7e1-dd73f272fd7e"
      },
      "source": [
        "print('Percentage of data labeled in a NO FALL: ', (1 - y.sum()/y.size)*100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of data labeled in a NO FALL:  92.83941864587027 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5DciPtILgP4"
      },
      "source": [
        "#### Taking the Data imbalance into account\n",
        "\n",
        "The first thing that we can do is to look at model assessment measures other than accuracy. Alternatives are:\n",
        "\n",
        "*The confusion matrix - the matrix of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN).\n",
        "\n",
        "*Precision/Specificity: how many selected instances are relevant = TP/(TP+FP)\n",
        "\n",
        "*Recall/Sensitivity: how many relevant instances are selected = TP/(TP+FN)\n",
        "\n",
        "*F1 score: harmonic mean of precision and recall = the harmonic mean of precission and recall.\n",
        "\n",
        "*ROC curves and AUC\n",
        "\n",
        "Thus we will firstly construct some models using the original data and compare them using the previously mentioned metrics, which are more adapted than accuracy in this case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gbEqvabOsMx"
      },
      "source": [
        "#### Which metrics is most relevant for our Project?\n",
        "\n",
        "In our case we are trying to predict falls. Knowing that a fall can have very bad consequences we really want to avoid misclassifying a fall as a 'no fall' and aren't as worried if we missclassify a 'no fall' as a fall. Thus, the most important metric is the true positive rate, or the recall. Thus, ROC curves and the AUCs might be of particular importance as they depend on the True Positive Rate and the False Positive Rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU9EMtNwojua"
      },
      "source": [
        "### Training some models\n",
        "We will firstly train some models using the original data so we can compare them once we deal with the imbalance problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF4EIyJuoRF5"
      },
      "source": [
        "#### Train and Test data sets\n",
        "\n",
        "Test set 25%, Train set 75%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJwTqXhidL4"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/4, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GxwEbQEZDnq"
      },
      "source": [
        "#Function to print the metrics\n",
        "def print_metrics(y, y_test):\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y).ravel()\n",
        "    #specificity = tn / (tn + fp)\n",
        "    #fpr, tpr, thresholds = metrics.roc_curve(y_test, y, pos_label=2)\n",
        "    print(\"Accuracy=\",float(\"{:.4f}\".format(metrics.accuracy_score(y_test, y))),\n",
        "          \"\\nBalanced Accuracy =\",float(\"{:.4f}\".format(balanced_accuracy_score(y_test,y))),\n",
        "          \"\\nTP = \", tp, \"FP = \", fp, \"TN  = \", tn, \"FN = \", fn,\n",
        "      \"\\nPrecision=\",float(\"{:.4f}\".format(metrics.precision_score(y_test, y))),\n",
        "      \"\\nRecall=\",float(\"{:.4f}\".format(metrics.recall_score(y_test, y))), \n",
        "      #\"True Negaive Rate=\",float(\"{:.4f}\".format(specificity)),\n",
        "      \"\\nF1 Score=\",float(\"{:.4f}\".format(metrics.f1_score(y_test, y))),\n",
        "      \"\\nAUC=\",float(\"{:.4f}\".format(roc_auc_score(y_test, y))))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IEBNVncFfOP"
      },
      "source": [
        "# Function to plot a boxplot for model comparison via cross validation for a given metric\n",
        "def box_cross_validation(metric_name, models_, classifiers_):\n",
        "    kfold = [StratifiedKFold(n_splits=10, shuffle=True, random_state=0) for i in range(len(models_))] # Stratified K Fold splits to preserve the original classes distribution\n",
        "    cv_scores = [cross_val_score(classifiers_[i], x, y, cv=kfold[i], scoring=metric_name) for i in range(len(models_))]\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 3.5))\n",
        "    fig.suptitle('Model Comparison')\n",
        "    ax = fig.add_subplot()\n",
        "    plt.boxplot(cv_scores)\n",
        "    ax.set(ylabel=metric_name)\n",
        "    ax.set_xticklabels(models_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2BZsniUor4V"
      },
      "source": [
        "#### Naive Bayes Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPyy7F2JogPq",
        "outputId": "95403e22-1d57-4f11-9406-e1672c0c6d4c"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "gnbfit = gnb.fit(x_train, y_train)\n",
        "y_bayes = gnbfit.predict(x_test)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_bayes, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9547 \n",
            "Balanced Accuracy = 0.9362 \n",
            "TP =  43 FP =  28 TN  =  631 FN =  4 \n",
            "Precision= 0.6056 \n",
            "Recall= 0.9149 \n",
            "F1 Score= 0.7288 \n",
            "AUC= 0.9362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3bthY3a_ZpR"
      },
      "source": [
        "### Looking at the metrics\n",
        "\n",
        "We observe that the precision is far away from 1, which means the model does missclassifies a lot of negative samples, resulting in many false positives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkLZ8bUYpHLD"
      },
      "source": [
        "#### Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESSIZOSqovwk",
        "outputId": "cde563a0-140a-4c13-ce7f-c3d43dd2f20d"
      },
      "source": [
        "lda = LinearDiscriminantAnalysis();\n",
        "ldafit=lda.fit(x_train,y_train)\n",
        "y_lda = ldafit.predict(x_test)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_lda,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9873 \n",
            "Balanced Accuracy = 0.9141 \n",
            "TP =  39 FP =  1 TN  =  658 FN =  8 \n",
            "Precision= 0.975 \n",
            "Recall= 0.8298 \n",
            "F1 Score= 0.8966 \n",
            "AUC= 0.9141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-HbZ6qmBKMc"
      },
      "source": [
        "## Comment on the metrics\n",
        "\n",
        "LDA does a better job in avoiding false positives, but it results in more false negatives, which gives it a worse recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "229BL31QpVpU"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDbl49JYpXA0",
        "outputId": "18e701ac-e03c-4f5b-8a6e-35f2a983ec36"
      },
      "source": [
        "logr = LogisticRegression(solver=\"lbfgs\")\n",
        "logrfit= logr.fit(x_train,y_train)\n",
        "y_logr = logrfit.predict(x_test)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_logr,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9887 \n",
            "Balanced Accuracy = 0.9347 \n",
            "TP =  41 FP =  2 TN  =  657 FN =  6 \n",
            "Precision= 0.9535 \n",
            "Recall= 0.8723 \n",
            "F1 Score= 0.9111 \n",
            "AUC= 0.9347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aER8VxlTEVzk"
      },
      "source": [
        "## Comment on the metrics results\n",
        "\n",
        "This is the highest F1 score so far"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bgzhTPpfR0"
      },
      "source": [
        "#### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxotUSKXpmmN",
        "outputId": "ef2be268-3cce-4d82-94d3-73f78295b0b1"
      },
      "source": [
        "# To choose a k we'll use a validation set \n",
        "x_train1, x_vald, y_train1, y_vald = train_test_split(x_train, y_train, test_size=0.20, random_state=0)\n",
        "knn = [KNeighborsClassifier(n_neighbors = i+1) for i in range(10)]\n",
        "knnfit = [knn[i].fit(x_train1,y_train1) for i in range(10)]\n",
        "y_knn = [knnfit[i].predict(x_vald) for i in range(10)]\n",
        "k = [metrics.f1_score(y_vald, y_knn[i]) for i in range(10)]\n",
        "np.where(k == np.amax(k))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 3, 5, 6, 7, 8, 9]),)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_IJKfz0pqmo",
        "outputId": "48b05238-7ebb-4296-d3d8-d2c070634a1c"
      },
      "source": [
        "# We know train the classifier with the original training set\n",
        "knn = KNeighborsClassifier(n_neighbors = 4)\n",
        "knnfit = knn.fit(x_train,y_train)\n",
        "y_knn = knnfit.predict(x_test)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_knn,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9873 \n",
            "Balanced Accuracy = 0.9043 \n",
            "TP =  38 FP =  0 TN  =  659 FN =  9 \n",
            "Precision= 1.0 \n",
            "Recall= 0.8085 \n",
            "F1 Score= 0.8941 \n",
            "AUC= 0.9043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS-qXVNSprgd"
      },
      "source": [
        "We obtain a 100% precision, that is, the model does not classify false positive samples. However, it still predicts false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PfVtuxhp0nr"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK6vvFTYqYtU",
        "outputId": "a21c1998-ffb5-4eec-a635-3dccaa24b281"
      },
      "source": [
        "tree = DecisionTreeClassifier(random_state=0)\n",
        "treefit = tree.fit(x_train, y_train)\n",
        "pred_tree = treefit.predict_proba(x_test)\n",
        "y_tree = np.argmax(pred_tree, axis=1)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_tree,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9844 \n",
            "Balanced Accuracy = 0.9126 \n",
            "TP =  39 FP =  3 TN  =  656 FN =  8 \n",
            "Precision= 0.9286 \n",
            "Recall= 0.8298 \n",
            "F1 Score= 0.8764 \n",
            "AUC= 0.9126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjjRMXifreNt"
      },
      "source": [
        "#### Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcXSRj3KriOq",
        "outputId": "27311fa4-0a7c-48f6-c121-2d1b6d5457e9"
      },
      "source": [
        "treebag = DecisionTreeClassifier(random_state=0)\n",
        "bagmod = BaggingClassifier(base_estimator=treebag)\n",
        "bagfit = bagmod.fit(x_train, y_train)\n",
        "\n",
        "pred_bag = bagfit.predict_proba(x_test)\n",
        "y_bag = np.argmax(pred_bag,axis = 1)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_bag, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9858 \n",
            "Balanced Accuracy = 0.9233 \n",
            "TP =  40 FP =  3 TN  =  656 FN =  7 \n",
            "Precision= 0.9302 \n",
            "Recall= 0.8511 \n",
            "F1 Score= 0.8889 \n",
            "AUC= 0.9233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dML3tZ2Srqih"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOLPaGFDrsOk",
        "outputId": "a01c3cb4-b983-4812-a32c-08bf1c4348b3"
      },
      "source": [
        "rf = RandomForestClassifier(random_state=0)\n",
        "rf_fit = rf.fit(x_train, y_train)\n",
        "pred_rf = rf_fit.predict_proba(x_test)\n",
        "\n",
        "y_rf=np.argmax(pred_rf,axis=1)\n",
        "\n",
        "# Metrics \n",
        "print_metrics(y_rf,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9873 \n",
            "Balanced Accuracy = 0.9141 \n",
            "TP =  39 FP =  1 TN  =  658 FN =  8 \n",
            "Precision= 0.975 \n",
            "Recall= 0.8298 \n",
            "F1 Score= 0.8966 \n",
            "AUC= 0.9141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na38nAnTrzsh"
      },
      "source": [
        "### Model Performance Summary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pK7ehYxRr5HN",
        "outputId": "49d87c49-3579-4c6b-b751-6eabb63be90a"
      },
      "source": [
        "models = ['Naive Bayes', 'LDA', 'Logistic Regression', 'KNN', 'Decision Tree', 'Bagging', 'Random Forest']\n",
        "rows_names = ['Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score','AUC']\n",
        "y_vector = [y_bayes, y_lda, y_logr, y_knn, y_tree, y_bag, y_rf]\n",
        "accuracy_vector = [round(metrics.accuracy_score(y_test, y),4) for y in y_vector]\n",
        "b_accuracy_vector = [round(balanced_accuracy_score(y_test,y),4) for y in y_vector]\n",
        "precision_vector = [round(metrics.precision_score(y_test, y),4) for y in y_vector]\n",
        "recall_vector = [round(metrics.recall_score(y_test, y),4) for y in y_vector]\n",
        "f1_vector = [round(metrics.f1_score(y_test, y),4) for y in y_vector]\n",
        "auc_vector = [round(roc_auc_score(y_test, y),4) for y in y_vector]\n",
        "summary_df = pd.DataFrame([accuracy_vector,b_accuracy_vector,precision_vector,recall_vector,f1_vector, auc_vector])\n",
        "summary_df.columns = models\n",
        "summary_df.index = rows_names\n",
        "summary_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>LDA</th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>KNN</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Bagging</th>\n",
              "      <th>Random Forest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.9547</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>0.9887</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>0.9844</td>\n",
              "      <td>0.9858</td>\n",
              "      <td>0.9873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <td>0.9362</td>\n",
              "      <td>0.9141</td>\n",
              "      <td>0.9347</td>\n",
              "      <td>0.9043</td>\n",
              "      <td>0.9126</td>\n",
              "      <td>0.9233</td>\n",
              "      <td>0.9141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.6056</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9535</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9286</td>\n",
              "      <td>0.9302</td>\n",
              "      <td>0.9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.9149</td>\n",
              "      <td>0.8298</td>\n",
              "      <td>0.8723</td>\n",
              "      <td>0.8085</td>\n",
              "      <td>0.8298</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.8298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1 Score</th>\n",
              "      <td>0.7288</td>\n",
              "      <td>0.8966</td>\n",
              "      <td>0.9111</td>\n",
              "      <td>0.8941</td>\n",
              "      <td>0.8764</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC</th>\n",
              "      <td>0.9362</td>\n",
              "      <td>0.9141</td>\n",
              "      <td>0.9347</td>\n",
              "      <td>0.9043</td>\n",
              "      <td>0.9126</td>\n",
              "      <td>0.9233</td>\n",
              "      <td>0.9141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Naive Bayes     LDA  ...  Bagging  Random Forest\n",
              "Accuracy                0.9547  0.9873  ...   0.9858         0.9873\n",
              "Balanced Accuracy       0.9362  0.9141  ...   0.9233         0.9141\n",
              "Precision               0.6056  0.9750  ...   0.9302         0.9750\n",
              "Recall                  0.9149  0.8298  ...   0.8511         0.8298\n",
              "F1 Score                0.7288  0.8966  ...   0.8889         0.8966\n",
              "AUC                     0.9362  0.9141  ...   0.9233         0.9141\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxJ7Ns6HKsZd"
      },
      "source": [
        "#### The previous table gives us a rough feeling for how these methods perform, because it takes into consideration only a single train-test split of our data. To get a better idea of their actual performences we will use cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__03w9djr7j4"
      },
      "source": [
        "## Corss-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FilYXOvtsEEi"
      },
      "source": [
        "models2 = ['GNB', 'LR', 'LDA', 'KNN','D. Tree','Bagging', 'R. Forest']\n",
        "classifiers = [GaussianNB(),LogisticRegression(),LinearDiscriminantAnalysis(),\n",
        "              KNeighborsClassifier(n_neighbors = 4),DecisionTreeClassifier(),\n",
        "              BaggingClassifier(base_estimator=DecisionTreeClassifier()),RandomForestClassifier()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4hEjePPsSfv"
      },
      "source": [
        "### Recall Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "uFfaY-dPsUqI",
        "outputId": "3aa9d765-933e-4c2c-9e4b-51a5c6a4a6b4"
      },
      "source": [
        "box_cross_validation('recall', models2, classifiers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2cADp4-QBB0"
      },
      "source": [
        "### Comment\n",
        "\n",
        "Surprisingly, the Naive Bayes classifier displays the best recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBULqebdHJui"
      },
      "source": [
        "## F1 comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "d9YHVfdHFeCy",
        "outputId": "b50443ab-fbc5-4e37-f2e3-baa34c365f30"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "box_cross_validation('f1', models2, classifiers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "oKVsoZ7HQQkj",
        "outputId": "e052c270-45f7-433e-97f3-d84d1be57ab4"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "box_cross_validation('roc_auc', models2, classifiers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Czs1JFqCZAA"
      },
      "source": [
        "## Comment about under-sampling\n",
        "\n",
        "Under-sampling represents a way in which we could create a balanced dataset out of our imbalanced one. However, as the rare class has only 200 samples and knowing that we have around 90 features this approach would result in underfitting. We could reduce the features, but we have no further information about the features to decide which ones are more relevant. Thus, we choose to not use a under-sampling approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPaCCERwKZeF"
      },
      "source": [
        "# Dealing with the Data Imbalance using ensemble methods\n",
        "\n",
        "In the next section we are going to balance our data set and use bagging to aggregate different learners in order to obtain an enseble model.\n",
        "The BalancedBaggingClassifier offers this option by first creating balanced datasets and then using them in the bagging process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaEq-A42Knfa"
      },
      "source": [
        "### Balenced Bagging - NBayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oqHOpNPMQdX",
        "outputId": "f083aa6b-4b4e-4f8f-fa50-3b1a4bf5b001"
      },
      "source": [
        "bagged_Nbays = BalancedBaggingClassifier(base_estimator =GaussianNB() )\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores1_NBayes = cross_val_score(bagged_Nbays, x, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores2_NBayes = cross_val_score(bagged_Nbays, x, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "scores3_NBayes = cross_val_score(bagged_Nbays, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "scores4_NBayes = cross_val_score(bagged_Nbays, x, y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Mean ROC AUC for bagged NBayes: %.3f' % np.mean(scores1_NBayes), '\\n')\n",
        "print('Mean F1 for bagged NBayes: %.3f' % np.mean(scores2_NBayes), '\\n')\n",
        "print('Mean balanced accuracy for bagged Nbayes: %.3f' % np.mean(scores3_NBayes), '\\n')\n",
        "print('Mean Recall for bagged Nbayes: %.3f' % np.mean(scores4_NBayes), '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC for bagged NBayes: 0.974 \n",
            "\n",
            "Mean F1 for bagged NBayes: 0.757 \n",
            "\n",
            "Mean balanced accuracy for bagged Nbayes: 0.950 \n",
            "\n",
            "Mean Recall for bagged Nbayes: 0.949 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xX9mzJnMtJ8"
      },
      "source": [
        "## Balanced Bagging - Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7faJHW8Mw9q",
        "outputId": "75f0e134-d446-4afe-d1de-199895432543"
      },
      "source": [
        "\n",
        "bagged_LDA = BalancedBaggingClassifier(base_estimator =LinearDiscriminantAnalysis() )\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores1_LDA = cross_val_score(bagged_LDA, x, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores2_LDA = cross_val_score(bagged_LDA, x, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "scores3_LDA = cross_val_score(bagged_LDA, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "scores4_LDA = cross_val_score(bagged_LDA, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "print('Mean ROC AUC for bagged LDA: %.3f' % np.mean(scores1_LDA), '\\n')\n",
        "print('Mean F1 for bagged LDA: %.3f' % np.mean(scores2_LDA), '\\n')\n",
        "print('Mean balanced accuracy for bagged LDA: %.3f' % np.mean(scores3_LDA), '\\n')\n",
        "print('Mean Recall for bagged LDA: %.3f' % np.mean(scores4_LDA), '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC for bagged LDA: 0.975 \n",
            "\n",
            "Mean F1 for bagged LDA: 0.871 \n",
            "\n",
            "Mean balanced accuracy for bagged LDA: 0.965 \n",
            "\n",
            "Mean Recall for bagged LDA: 0.962 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEuIIBMqNY_p"
      },
      "source": [
        "## Balance Bagging -  Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Wx9A-hNbSg",
        "outputId": "5be898df-a7c0-4c04-be93-74e4f9077ddf"
      },
      "source": [
        "\n",
        "bagged_LR = BalancedBaggingClassifier(base_estimator =LogisticRegression() )\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores1_LR = cross_val_score(bagged_LR, x, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores2_LR = cross_val_score(bagged_LR, x, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "scores3_LR = cross_val_score(bagged_LR, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "scores4_LR = cross_val_score(bagged_LR, x, y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "print('Mean ROC AUC for bagged LR: %.3f' % np.mean(scores1_LR), '\\n')\n",
        "print('Mean F1 for bagged LR: %.3f' % np.mean(scores2_LR), '\\n')\n",
        "print('Mean balanced accuracy for bagged LR: %.3f' % np.mean(scores3_LR), '\\n')\n",
        "print('Mean Recall for bagged LR: %.3f' % np.mean(scores4_LR), '\\n')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC for bagged LR: 0.986 \n",
            "\n",
            "Mean F1 for bagged LR: 0.879 \n",
            "\n",
            "Mean balanced accuracy for bagged LR: 0.964 \n",
            "\n",
            "Mean Recall for bagged LR: 0.947 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjXkYc33NmXh"
      },
      "source": [
        "## Balenced Bagging - KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl3O5p90Npkk",
        "outputId": "2741f8fb-8990-47eb-b25f-5ab912dc3cff"
      },
      "source": [
        "\n",
        "bagged_KNN = BalancedBaggingClassifier(base_estimator =KNeighborsClassifier() )\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores1_KNN = cross_val_score(bagged_KNN, x, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores2_KNN = cross_val_score(bagged_KNN, x, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "scores3_KNN = cross_val_score(bagged_KNN, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "scores4_KNN = cross_val_score(bagged_KNN, x, y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "print('Mean ROC AUC for bagged KNN: %.3f' % np.mean(scores1_KNN), '\\n')\n",
        "print('Mean F1 for bagged KNN: %.3f' % np.mean(scores2_KNN), '\\n')\n",
        "print('Mean balanced accuracy for bagged KNN: %.3f' % np.mean(scores3_KNN), '\\n')\n",
        "print('Mean Recall for bagged KNN: %.3f' % np.mean(scores4_KNN), '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC for bagged KNN: 0.988 \n",
            "\n",
            "Mean F1 for bagged KNN: 0.843 \n",
            "\n",
            "Mean balanced accuracy for bagged KNN: 0.960 \n",
            "\n",
            "Mean Recall for bagged KNN: 0.946 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWZzbKr8OD7y"
      },
      "source": [
        "## Balanced Bagging - Decission trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFNzPrnwN3n_",
        "outputId": "05c78c2a-bb19-4fd7-c94e-43a1ae9b7e13"
      },
      "source": [
        "bagged_DT = BalancedBaggingClassifier()\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores1_DT = cross_val_score(bagged_DT, x, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores2_DT = cross_val_score(bagged_DT, x, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "scores3_DT = cross_val_score(bagged_DT, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "scores4_DT = cross_val_score(bagged_DT, x, y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "print('Mean ROC AUC for bagged DT: %.3f' % np.mean(scores1_DT), '\\n')\n",
        "print('Mean F1 for bagged DT: %.3f' % np.mean(scores2_DT), '\\n')\n",
        "print('Mean balanced accuracy for bagged DT: %.3f' % np.mean(scores3_DT), '\\n')\n",
        "print('Mean Recall for bagged DT: %.3f' % np.mean(scores4_DT), '\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC for bagged DT: 0.980 \n",
            "\n",
            "Mean F1 for bagged DT: 0.874 \n",
            "\n",
            "Mean balanced accuracy for bagged DT: 0.958 \n",
            "\n",
            "Mean Recall for bagged DT: 0.932 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbtTvH_JzEtL"
      },
      "source": [
        "## Balanced Random Forest\n",
        "\n",
        "Random Forest is inherently an ensemble method and we already observed that it perfomed fairly well in the previous section. Similar to the BalancedBaggingClassifier we can devide the dataset in balanced subsamples using the 'class_weight' function of the sklearn.RandomForestClassifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flG5Ma8vzDx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8231744-ba07-450e-c8fc-b22a89ba4519"
      },
      "source": [
        "RF_balanced = RandomForestClassifier(n_estimators=15, class_weight='balanced_subsample')\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "scores1_DT = cross_val_score(RF_balanced, x, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "scores2_DT = cross_val_score(RF_balanced, x, y, scoring='f1', cv=cv, n_jobs=-1)\n",
        "scores3_DT = cross_val_score(RF_balanced, x, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
        "scores4_DT = cross_val_score(RF_balanced, x, y, scoring='recall', cv=cv, n_jobs=-1)\n",
        "\n",
        "\n",
        "  \n",
        "print('Mean ROC AUC for ballanced RF: %.3f' % np.mean(scores1_DT), '\\n')\n",
        "print('Mean F1 for ballanced RF: %.3f' % np.mean(scores2_DT), '\\n')\n",
        "print('Mean balanced accuracy for ballanced RF: %.3f' % np.mean(scores3_DT), '\\n')\n",
        "print('Mean Recall for ballanced RF: %.3f' % np.mean(scores4_DT), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC for ballanced RF: 0.980 \n",
            "\n",
            "Mean F1 for ballanced RF: 0.925 \n",
            "\n",
            "Mean balanced accuracy for ballanced RF: 0.941 \n",
            "\n",
            "Mean Recall for ballanced RF: 0.884 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWHvYIF8LSyy"
      },
      "source": [
        "## Let's use boxplots to look at the previous statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X9PXm3_uZJX"
      },
      "source": [
        "classifiers2 = [BalancedBaggingClassifier(base_estimator =GaussianNB()),\n",
        "                BalancedBaggingClassifier(base_estimator =LogisticRegression()), \n",
        "                BalancedBaggingClassifier(base_estimator =LinearDiscriminantAnalysis()),\n",
        "                BalancedBaggingClassifier(base_estimator =KNeighborsClassifier()),\n",
        "                BalancedBaggingClassifier(),\n",
        "                RandomForestClassifier(n_estimators=15, class_weight='balanced_subsample')]\n",
        "models3 = ['B_GNB', 'B_LR', 'B_LDA', 'B_KNN', 'B_DT', 'B_RF']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Lt8F9uQnfH"
      },
      "source": [
        "\n",
        "box_cross_validation('recall', models3, classifiers2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIm0WU_5RNHQ"
      },
      "source": [
        "We now plotted some boxgraphs using cross validation for a reapeated stratified 10-fold. The results for recall look similar for all the used ensemble methods.\n",
        "We observe that bagging our models results in a higher True Positive Rate, \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "Aal4rNWyMvzB",
        "outputId": "70fa5d1c-f611-4742-d767-9e569e432092"
      },
      "source": [
        "box_cross_validation('f1', models3, classifiers2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 396x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XryEt3pmRZej"
      },
      "source": [
        "Watching the F1 score, we see a considerable difference between the bagged Naive Bayes classifer and the rest of the used methods. Another interesting aspect is that the balanced Random Forest has the best F1 score wheras it had the poorest Recall score, but not considerably worse.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "zXmv3Bi6Q895",
        "outputId": "84255a79-e762-43c8-81f3-71f602587afe"
      },
      "source": [
        "box_cross_validation('roc_auc', models3, classifiers2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 396x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgRqp9LlWTRb"
      },
      "source": [
        "Watching our results we consider that the used ensemble methods are worthy of further investigation for our given problem. However, we would probably drop the Bagged Naive Bayes classifier due to its poor precision score. Judging by our Recall score we would prefer the bagged Logistic Regression and we would pick the Balanced Random Forest if we wanted a better F1 score.\n"
      ]
    }
  ]
}